# üêæ End-to-End Image Classification: Pets vs. Non-Pets

![Training History](training_history.png)

## üìñ Project Overview
This project is a complete, end-to-end image classification pipeline designed to distinguish between **Pets** (Dogs, Cats, Birds, Rabbits) and **Non-Pets** (Wild Animals, Humans, Objects, Places). 

Built using **PyTorch** and **MobileNetV2**, the system not only classifies images into broad categories but also provides fine-grained identification, ecological data (dietary habits and natural habitats), and implements intelligent guardrails to ensure accuracy for visually similar wild species.

---

## ‚ú® Key Features

### 1. üß† Dual-Model Inference
The system utilizes a powerful two-stage inference process:
- **Primary Classifier**: A custom-trained MobileNetV2 model that performs the broad classification between "Pets" and "Non-Pets".
- **Specific Identifier**: A pre-trained ImageNet model that identifies the exact breed or species (e.g., "Golden Retriever", "Egyptian Cat", "Lion").

### 2. ü¶Å Wild Animal Guardrails
One of the core strengths of this project is its **intelligent override logic**. Since wild felines (like lions or tigers) share many visual features with domestic cats, standard models can often misclassify them. This system cross-references the specific identified name with a "Wild Animal" database to force a "Non-Pet" classification for species like:
- Lions, Tigers, Leopards, Cheetahs
- Wolves, Foxes, Bears, Hyenas, and more.

### 3. üçñ Ecological Information
For every animal identified, the application provides:
- **Food Type**: Categorized as **Herbivorous**, **Carnivorous**, or **Omnivorous**.
- **Habitation**: Information about the animal's natural habitat (e.g., "African Savannas", "Domesticated - Human Homes").

### 4. üé® Premium Web Interface
A modern, responsive dashboard built with Flask and Vanilla CSS, featuring:
- Drag-and-drop or click-to-upload functionality.
- Real-time result cards with confidence percentages.
- Glassmorphism design aesthetics and smooth micro-animations.

---

## üõ†Ô∏è Technology Stack
- **Framework**: PyTorch
- **Architecture**: MobileNetV2 (Transfer Learning)
- **Web Backend**: Flask (Python)
- **Frontend**: HTML5, CSS3 (Modern UI), JavaScript
- **Image Processing**: Pillow (PIL)
- **Deployment**: Git/GitHub

---

## üìÇ Project Structure
```text
image/
‚îú‚îÄ‚îÄ app.py                # Flask Web Server & Inference Logic
‚îú‚îÄ‚îÄ train.py              # PyTorch Training Pipeline
‚îú‚îÄ‚îÄ classifier_model.pth  # Trained Model Weights
‚îú‚îÄ‚îÄ classes.txt           # Category Labels
‚îú‚îÄ‚îÄ training_history.png  # Accuracy/Loss Visualization
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îú‚îÄ‚îÄ css/style.css     # Premium UI Styling
‚îÇ   ‚îî‚îÄ‚îÄ uploads/          # Temporary storage for uploaded images
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html        # Main Dashboard Template
‚îî‚îÄ‚îÄ README.md             # Project Documentation
```

---

## üöÄ Getting Started

### Prerequisites
- Python 3.8+
- PyTorch & Torchvision
- Flask

### Installation

1. **Clone the Project**
   ```bash
   git clone https://github.com/4mh23cs043-collab/image.git
   cd image
   ```

2. **Install Dependencies**
   ```bash
   pip install torch torchvision flask pillow
   ```

3. **Launch the Application**
   ```bash
   python app.py
   ```

4. **Access the Dashboard**
   Open your browser and navigate to:
   `http://127.0.0.1:5001`

---

## üìä Model Training & Results
The model was trained using **Transfer Learning** on a curated dataset of over 7,000 images. By freezing the early layers of **MobileNetV2** and training a custom classification head, we achieved:
- High validation accuracy (>90%).
- Robust performance on diverse animal breeds.
- Low latency inference optimized for CPU environments.

---

## ü§ù Contribution
This project was developed as a collaborative effort to demonstrate a production-ready AI application. Feel free to fork the repository and submit pull requests for any enhancements!

---
*Created by Nuthan & The AI Pair Programming Team*
